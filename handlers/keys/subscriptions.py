import asyncio
import base64
import random
import re
import time
import urllib.parse

from datetime import datetime

import aiohttp
import asyncpg
import pytz

from aiohttp import web

from config import (
    DATABASE_URL,
    PROJECT_NAME,
    SUPERNODE,
    SUPPORT_CHAT_URL,
    TOTAL_GB,
    TRANSITION_DATE_STR,
    USERNAME_BOT,
    USE_COUNTRY_SELECTION,
)
from database import get_key_details, get_servers
from handlers.utils import convert_to_bytes
from logger import logger


async def fetch_url_content(url: str, identifier: str) -> list[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ–¥–ø–∏—Å–∫–∏ –ø–æ URL –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç –µ–≥–æ.

    Args:
        url: URL –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        identifier: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (tg_id –∏–ª–∏ email)

    Returns:
        –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –∏–∑ –ø–æ–¥–ø–∏—Å–∫–∏
    """
    try:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–∏–µ URL: {url} –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}")
        timeout = aiohttp.ClientTimeout(total=5)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, ssl=False) as response:
                if response.status == 200:
                    content = await response.text()
                    logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç —Å {url} –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}")
                    return base64.b64decode(content).decode("utf-8").split("\n")
                else:
                    logger.error(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å {url} –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}, —Å—Ç–∞—Ç—É—Å: {response.status}"
                    )
                    return []
    except TimeoutError:
        logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ {url} –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}")
        return []
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ {url} –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}: {e}")
        return []


async def combine_unique_lines(urls: list[str], identifier: str, query_string: str) -> list[str]:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥–ø–∏—Å–∫–∏ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö URL, —É–¥–∞–ª—è—è –¥—É–±–ª–∏–∫–∞—Ç—ã.

    Args:
        urls: –°–ø–∏—Å–æ–∫ URL –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–æ–∫
        identifier: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (tg_id –∏–ª–∏ email)
        query_string: –°—Ç—Ä–æ–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∫ URL

    Returns:
        –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –∏–∑ –≤—Å–µ—Ö –ø–æ–¥–ø–∏—Å–æ–∫
    """
    if SUPERNODE:
        logger.info(f"–†–µ–∂–∏–º SUPERNODE –∞–∫—Ç–∏–≤–µ–Ω. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Å—ã–ª–∫—É –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}")
        if not urls:
            return []
        url_with_query = f"{urls[0]}?{query_string}" if query_string else urls[0]
        return await fetch_url_content(url_with_query, identifier)

    logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å–æ–∫ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}, –∑–∞–ø—Ä–æ—Å: {query_string}")
    urls_with_query = [f"{url}?{query_string}" if query_string else url for url in urls]
    logger.info(f"–°–æ—Å—Ç–∞–≤–ª–µ–Ω—ã URL-–∞–¥—Ä–µ—Å–∞: {urls_with_query}")

    tasks = [fetch_url_content(url, identifier) for url in urls_with_query]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    all_lines = set()
    for lines in results:
        all_lines.update(filter(None, lines))
    logger.info(
        f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(all_lines)} —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: {identifier}"
    )
    return list(all_lines)


async def get_subscription_urls(server_id: str, email: str, conn, include_remnawave_key: str = None) -> list[str]:
    urls = []
    if USE_COUNTRY_SELECTION:
        logger.info(f"[Sub] –°—Ç—Ä–∞–Ω–∞-—Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–µ–Ω. –ò—â–µ–º —Å–µ—Ä–≤–µ—Ä {server_id}.")
        server_data = await conn.fetchrow("SELECT subscription_url FROM servers WHERE server_name = $1", server_id)
        if server_data and server_data["subscription_url"]:
            urls.append(f"{server_data['subscription_url']}/{email}")
    else:
        servers = await get_servers(conn)
        cluster_servers = servers.get(server_id, [])
        for server in cluster_servers:
            if url := server.get("subscription_url"):
                urls.append(f"{url}/{email}")

    if include_remnawave_key:
        urls.append(include_remnawave_key)
        logger.info(f"[Sub] –î–æ–±–∞–≤–ª–µ–Ω–∞ Remnawave —Å—Å—ã–ª–∫–∞: {include_remnawave_key}")

    logger.info(f"[Sub] –°–ø–∏—Å–æ–∫ URL –ø–æ–¥–ø–∏—Å–æ–∫: {urls}")
    return urls


def get_transition_timestamp() -> int:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É –ø–µ—Ä–µ—Ö–æ–¥–∞ —Å —É—á–µ—Ç–æ–º —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ –ú–æ—Å–∫–≤—ã.

    Returns:
        –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
    """
    moscow_tz = pytz.timezone("Europe/Moscow")
    transition_date_naive = datetime.strptime(TRANSITION_DATE_STR, "%Y-%m-%d %H:%M:%S")
    transition_date = moscow_tz.localize(transition_date_naive)
    transition_timestamp_ms = int(transition_date.timestamp() * 1000)
    return transition_timestamp_ms


def calculate_traffic(cleaned_subscriptions: list[str], expiry_time_ms: int | None) -> str:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–∞—Ñ–∏–∫–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–¥–ø–∏—Å–æ–∫.

    Args:
        cleaned_subscriptions: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –ø–æ–¥–ø–∏—Å–∫–∏
        expiry_time_ms: –í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–∫–∏ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç—Ä–∞—Ñ–∏–∫–µ
    """
    expire_timestamp = int(expiry_time_ms / 1000) if expiry_time_ms else 0

    if TOTAL_GB != 0:
        country_remaining = {}
        for line in cleaned_subscriptions:
            if "#" not in line:
                continue

            try:
                _, meta = line.split("#", 1)
            except ValueError:
                continue

            parts = meta.split("-")
            country = parts[0].strip()
            remaining_str = parts[1].strip() if len(parts) == 2 else ""

            if remaining_str:
                remaining_str = remaining_str.replace(",", ".")
                m_total = re.search(r"([\d\.]+)\s*([GMKTB]B)", remaining_str, re.IGNORECASE)
                if m_total:
                    value = float(m_total.group(1))
                    unit = m_total.group(2).upper()
                    remaining_bytes = convert_to_bytes(value, unit)
                    country_remaining[country] = remaining_bytes

        num_countries = len(country_remaining)
        issued_per_country = TOTAL_GB
        total_traffic_bytes = issued_per_country * num_countries
        consumed_traffic_bytes = total_traffic_bytes - sum(country_remaining.values())

        if consumed_traffic_bytes < 0:
            consumed_traffic_bytes = 0
    else:
        consumed_traffic_bytes = 1
        total_traffic_bytes = 0

    return f"upload=0; download={consumed_traffic_bytes}; total={total_traffic_bytes}; expire={expire_timestamp}"


def clean_subscription_line(line: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –ø–æ–¥–ø–∏—Å–∫–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

    Args:
        line: –ò—Å—Ö–æ–¥–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ–¥–ø–∏—Å–∫–∏

    Returns:
        –û—á–∏—â–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ–¥–ø–∏—Å–∫–∏
    """
    if "#" not in line:
        return line

    try:
        base, meta = line.split("#", 1)
    except ValueError:
        return line

    parts = meta.split("-")
    country = parts[0].strip() if parts else ""
    traffic = ""

    for part in parts[1:]:
        part_decoded = urllib.parse.unquote(part).strip()
        if re.search(r"\d+(?:[.,]\d+)?\s*(?:GB|MB|KB|TB)", part_decoded, re.IGNORECASE):
            traffic = part_decoded
            break

    meta_clean = f"{country} - {traffic}" if traffic else country
    return base + "#" + meta_clean


def format_time_left(expiry_time_ms: int | None) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è –ø–æ–¥–ø–∏—Å–∫–∏.

    Args:
        expiry_time_ms: –í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è –ø–æ–¥–ø–∏—Å–∫–∏ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

    Returns:
        –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –æ—Å—Ç–∞–≤—à–∏–º—Å—è –≤—Ä–µ–º–µ–Ω–µ–º
    """
    if not expiry_time_ms:
        return "N/A"

    now_ms = int(time.time() * 1000)
    remaining_sec = max((expiry_time_ms - now_ms) / 1000, 0)
    days = int(remaining_sec // 86400)
    hours = int((remaining_sec % 86400) // 3600)

    return f"{days}D,{hours}H ‚è≥" if days else f"{hours}H ‚è≥"


def prepare_headers(
    user_agent: str, project_name: str, subscription_info: str, subscription_userinfo: str
) -> dict[str, str]:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç User-Agent –∫–ª–∏–µ–Ω—Ç–∞.

    Args:
        user_agent: User-Agent –∫–ª–∏–µ–Ω—Ç–∞
        project_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
        subscription_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–¥–ø–∏—Å–∫–µ
        subscription_userinfo: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç—Ä–∞—Ñ–∏–∫–µ

    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –æ—Ç–≤–µ—Ç–∞
    """
    if "Happ" in user_agent:
        encoded_project_name = f"{project_name}"
        announce_str = f"‚ÜñÔ∏è–ë–æ—Ç | {subscription_info} | –ü–æ–¥–¥–µ—Ä–∂–∫–∞‚ÜóÔ∏è"
        return {
            "Content-Type": "text/plain; charset=utf-8",
            "Content-Disposition": "inline",
            "profile-update-interval": "3",
            "profile-title": "base64:" + base64.b64encode(encoded_project_name.encode("utf-8")).decode("utf-8"),
            "support-url": SUPPORT_CHAT_URL,
            "announce": "base64:" + base64.b64encode(announce_str.encode("utf-8")).decode("utf-8"),
            "profile-web-page-url": f"https://t.me/{USERNAME_BOT}",
            "subscription-userinfo": subscription_userinfo,
        }
    elif "Hiddify" in user_agent:
        parts = subscription_info.split(" - ")[0].split(": ")
        key_info = parts[1] if len(parts) > 1 else parts[0]

        encoded_project_name = f"{project_name}\nüìÑ –ü–æ–¥–ø–∏—Å–∫–∞: {key_info}"
        return {
            "profile-update-interval": "3",
            "profile-title": "base64:" + base64.b64encode(encoded_project_name.encode("utf-8")).decode("utf-8"),
            "subscription-userinfo": subscription_userinfo,
        }
    else:
        encoded_project_name = f"{project_name}\n{subscription_info}"
        return {
            "Content-Type": "text/plain; charset=utf-8",
            "Content-Disposition": "inline",
            "profile-update-interval": "3",
            "profile-title": "base64:" + base64.b64encode(encoded_project_name.encode("utf-8")).decode("utf-8"),
        }


async def handle_subscription(request: web.Request, old_subscription: bool = False) -> web.Response:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–¥–ø–∏—Å–∫—É (—Å—Ç–∞—Ä—É—é –∏–ª–∏ –Ω–æ–≤—É—é).

    Args:
        request: –û–±—ä–µ–∫—Ç –∑–∞–ø—Ä–æ—Å–∞
        old_subscription: –§–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ —Ç–∏–ø –ø–æ–¥–ø–∏—Å–∫–∏ (—Å—Ç–∞—Ä–∞—è –∏–ª–∏ –Ω–æ–≤–∞—è)

    Returns:
        –û—Ç–≤–µ—Ç —Å –ø–æ–¥–ø–∏—Å–∫–æ–π –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ–± –æ—à–∏–±–∫–µ
    """
    email = request.match_info.get("email")
    tg_id = request.match_info.get("tg_id") if not old_subscription else None

    if not email or (not old_subscription and not tg_id):
        logger.warning("–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
        return web.Response(text="‚ùå –ù–µ–≤–µ—Ä–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞.", status=400)

    logger.info(
        f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {'—Å—Ç–∞—Ä–æ–≥–æ' if old_subscription else '–Ω–æ–≤–æ–≥–æ'} –∫–ª–∏–µ–Ω—Ç–∞: email={email}, tg_id={tg_id}"
    )

    conn = await asyncpg.connect(DATABASE_URL)
    try:
        client_data = await get_key_details(email, conn)
        if not client_data:
            logger.warning(f"–ö–ª–∏–µ–Ω—Ç —Å email {email} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ.")
            return web.Response(text="‚ùå –ö–ª–∏–µ–Ω—Ç —Å —Ç–∞–∫–∏–º email –Ω–µ –Ω–∞–π–¥–µ–Ω.", status=404)

        stored_tg_id = client_data.get("tg_id")
        server_id = client_data["server_id"]

        if not old_subscription and int(tg_id) != int(stored_tg_id):
            logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π tg_id –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ —Å email {email}.")
            return web.Response(text="‚ùå –ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –ü–æ–ª—É—á–∏—Ç–µ —Å–≤–æ–π –∫–ª—é—á –≤ –±–æ—Ç–µ.", status=403)

        if old_subscription:
            created_at_ms = client_data["created_at"]
            created_at_datetime = datetime.utcfromtimestamp(created_at_ms / 1000)
            logger.info(f"created_at –¥–ª—è {email}: {created_at_datetime}, server_id: {server_id}")

            transition_timestamp_ms = get_transition_timestamp()
            logger.info(f"–í—Ä–µ–º—è –ø–µ—Ä–µ—Ö–æ–¥–∞ (—Å —É—á–µ—Ç–æ–º —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ –ú–æ—Å–∫–≤—ã): {transition_timestamp_ms}")

            if created_at_ms >= transition_timestamp_ms:
                logger.info(f"–ö–ª–∏–µ–Ω—Ç —Å email {email} —è–≤–ª—è–µ—Ç—Å—è –Ω–æ–≤—ã–º.")
                return web.Response(text="‚ùå –≠—Ç–∞ —Å—Å—ã–ª–∫–∞ —É—Å—Ç–∞—Ä–µ–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±–Ω–æ–≤–∏—Ç–µ —Å—Å—ã–ª–∫—É.", status=400)

        expiry_time_ms = client_data.get("expiry_time")
        time_left = format_time_left(expiry_time_ms)

        urls = await get_subscription_urls(
    server_id, email, conn, include_remnawave_key=client_data.get("remnawave_link")
)

        if not urls:
            return web.Response(text="‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω.", status=404)

        query_string = request.query_string if not old_subscription else ""
        combined_subscriptions = await combine_unique_lines(urls, tg_id or email, query_string)
        random.shuffle(combined_subscriptions)

        cleaned_subscriptions = [clean_subscription_line(line) for line in combined_subscriptions]

        base64_encoded = base64.b64encode("\n".join(cleaned_subscriptions).encode("utf-8")).decode("utf-8")
        subscription_info = f"üìÑ –ü–æ–¥–ø–∏—Å–∫–∞: {email} - {time_left}"

        user_agent = request.headers.get("User-Agent", "")
        subscription_userinfo = calculate_traffic(cleaned_subscriptions, expiry_time_ms)
        headers = prepare_headers(user_agent, PROJECT_NAME, subscription_info, subscription_userinfo)

        logger.info(f"–í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è email: {email}")
        return web.Response(text=base64_encoded, headers=headers)
    finally:
        await conn.close()


async def handle_old_subscription(request: web.Request) -> web.Response:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤."""
    return await handle_subscription(request, old_subscription=True)


async def handle_new_subscription(request: web.Request) -> web.Response:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤."""
    return await handle_subscription(request, old_subscription=False)
