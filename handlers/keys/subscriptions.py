import asyncio
import base64
import random
import re
import time
import urllib.parse
from datetime import datetime

import aiohttp
import asyncpg
from aiohttp import web

from config import (
    DATABASE_URL, PROJECT_NAME, SUB_MESSAGE, SUPERNODE,
    TRANSITION_DATE_STR, USE_COUNTRY_SELECTION, SUPPORT_CHAT_URL, USERNAME_BOT, TOTAL_GB
)
from database import get_key_details, get_servers
from logger import logger

db_pool = None

async def init_db_pool():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω."""
    global db_pool
    if not db_pool:
        db_pool = await asyncpg.create_pool(dsn=DATABASE_URL, min_size=5, max_size=20)


async def fetch_url_content(url, tg_id):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ–¥–ø–∏—Å–∫–∏ –ø–æ URL –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ—Ç –µ–≥–æ."""
    try:
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–∏–µ URL: {url} –¥–ª—è tg_id: {tg_id}")
        timeout = aiohttp.ClientTimeout(total=5)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, ssl=False) as response:
                if response.status == 200:
                    content = await response.text()
                    logger.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –∫–æ–Ω—Ç–µ–Ω—Ç —Å {url} –¥–ª—è tg_id: {tg_id}")
                    return base64.b64decode(content).decode("utf-8").split("\n")
                else:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å {url} –¥–ª—è tg_id: {tg_id}, —Å—Ç–∞—Ç—É—Å: {response.status}")
                    return []
    except TimeoutError:
        logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ {url} –¥–ª—è tg_id: {tg_id}")
        return []
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ {url} –¥–ª—è tg_id: {tg_id}: {e}")
        return []


async def combine_unique_lines(urls, tg_id, query_string):
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥–ø–∏—Å–∫–∏, —É–¥–∞–ª—è—è –¥—É–±–ª–∏–∫–∞—Ç—ã."""
    if SUPERNODE:
        logger.info(f"–†–µ–∂–∏–º SUPERNODE –∞–∫—Ç–∏–≤–µ–Ω. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Å—ã–ª–∫—É –¥–ª—è tg_id: {tg_id}")
        if not urls:
            return []
        url_with_query = f"{urls[0]}?{query_string}" if query_string else urls[0]
        return await fetch_url_content(url_with_query, tg_id)

    logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–æ–¥–ø–∏—Å–æ–∫ –¥–ª—è tg_id: {tg_id}, –∑–∞–ø—Ä–æ—Å: {query_string}")
    urls_with_query = [f"{url}?{query_string}" if query_string else url for url in urls]
    logger.info(f"–°–æ—Å—Ç–∞–≤–ª–µ–Ω—ã URL-–∞–¥—Ä–µ—Å–∞: {urls_with_query}")

    tasks = [fetch_url_content(url, tg_id) for url in urls_with_query]
    results = await asyncio.gather(*tasks)

    all_lines = set()
    for lines in results:
        all_lines.update(filter(None, lines))

    logger.info(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(all_lines)} —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∏ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–ª—è tg_id: {tg_id}")
    return list(all_lines)


transition_date = datetime.strptime(TRANSITION_DATE_STR, "%Y-%m-%d %H:%M:%S")
transition_timestamp_ms = int(transition_date.timestamp() * 1000)
transition_timestamp_ms_adjusted = transition_timestamp_ms - (3 * 60 * 60 * 1000)
logger.info(f"–í—Ä–µ–º—è –ø–µ—Ä–µ—Ö–æ–¥–∞ (—Å –ø–æ–ø—Ä–∞–≤–∫–æ–π –Ω–∞ —á–∞—Å–æ–≤–æ–π –ø–æ—è—Å): {transition_timestamp_ms_adjusted}")


async def get_subscription_urls(server_id: str, email: str, conn) -> list:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–ª–∞–≥–∞ USE_COUNTRY_SELECTION
    –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ URL-–∞–¥—Ä–µ—Å–æ–≤ –¥–ª—è –ø–æ–¥–ø–∏—Å–∫–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.
    """
    if USE_COUNTRY_SELECTION:
        logger.info(f"–†–µ–∂–∏–º –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä–∞–Ω—ã –∞–∫—Ç–∏–≤–µ–Ω. –ò—â–µ–º —Å–µ—Ä–≤–µ—Ä {server_id} –≤ –ë–î.")
        server_data = await conn.fetchrow(
            "SELECT subscription_url FROM servers WHERE server_name = $1", server_id
        )
        if not server_data:
            logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω —Å–µ—Ä–≤–µ—Ä {server_id} –≤ –ë–î!")
            return []
        subscription_url = server_data["subscription_url"]
        urls = [f"{subscription_url}/{email}"]
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–ø–∏—Å–∫—É {urls[0]}")
        return urls

    servers = await get_servers()
    logger.info(f"–†–µ–∂–∏–º –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä–∞–Ω—ã –æ—Ç–∫–ª—é—á–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª–∞—Å—Ç–µ—Ä {server_id}.")
    cluster_servers = servers.get(server_id, [])
    if not cluster_servers:
        logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è {server_id}")
        return []
    urls = [f"{server['subscription_url']}/{email}" for server in cluster_servers]
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(urls)} URL-–∞–¥—Ä–µ—Å–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ {server_id}")
    return urls


async def handle_subscription(request, old_subscription=False):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–¥–ø–∏—Å–∫—É (—Å—Ç–∞—Ä—É—é –∏–ª–∏ –Ω–æ–≤—É—é)."""
    email = request.match_info.get("email")
    tg_id = request.match_info.get("tg_id") if not old_subscription else None

    if not email or (not old_subscription and not tg_id):
        logger.warning("–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
        return web.Response(text="‚ùå –ù–µ–≤–µ—Ä–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞.", status=400)

    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è {'—Å—Ç–∞—Ä–æ–≥–æ' if old_subscription else '–Ω–æ–≤–æ–≥–æ'} –∫–ª–∏–µ–Ω—Ç–∞: email={email}, tg_id={tg_id}")
    await init_db_pool()

    async with db_pool.acquire() as conn:
        client_data = await get_key_details(email, conn)
        if not client_data:
            logger.warning(f"–ö–ª–∏–µ–Ω—Ç —Å email {email} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ.")
            return web.Response(text="‚ùå –ö–ª–∏–µ–Ω—Ç —Å —Ç–∞–∫–∏–º email –Ω–µ –Ω–∞–π–¥–µ–Ω.", status=404)

        stored_tg_id = client_data.get("tg_id")
        server_id = client_data["server_id"]

        if not old_subscription and str(tg_id) != str(stored_tg_id):
            logger.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π tg_id –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ —Å email {email}.")
            return web.Response(text="‚ùå –ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ. –ü–æ–ª—É—á–∏—Ç–µ —Å–≤–æ–π –∫–ª—é—á –≤ –±–æ—Ç–µ.", status=403)

        if old_subscription:
            created_at_ms = client_data["created_at"]
            created_at_datetime = datetime.utcfromtimestamp(created_at_ms / 1000)
            logger.info(f"created_at –¥–ª—è {email}: {created_at_datetime}, server_id: {server_id}")
            if created_at_ms >= transition_timestamp_ms_adjusted:
                logger.info(f"–ö–ª–∏–µ–Ω—Ç —Å email {email} —è–≤–ª—è–µ—Ç—Å—è –Ω–æ–≤—ã–º.")
                return web.Response(text="‚ùå –≠—Ç–∞ —Å—Å—ã–ª–∫–∞ —É—Å—Ç–∞—Ä–µ–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±–Ω–æ–≤–∏—Ç–µ —Å—Å—ã–ª–∫—É.", status=400)

        urls = await get_subscription_urls(server_id, email, conn)
        if not urls:
            return web.Response(text="‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω.", status=404)

        query_string = request.query_string if not old_subscription else ""
        combined_subscriptions = await combine_unique_lines(urls, tg_id or email, query_string)
        random.shuffle(combined_subscriptions)

        time_left = None
        for line in combined_subscriptions:
            if "#" in line:
                try:
                    _, meta = line.split("#", 1)
                except ValueError:
                    continue
                parts = meta.split("-")
                candidate = parts[-1].strip() if parts else ""
                candidate_decoded = urllib.parse.unquote(candidate)
                m = re.search(
                    r'(?:(\d+)\s*[Dd]\s*,?\s*)?(\d+)\s*[Hh][^\d]*',
                    candidate_decoded,
                    re.IGNORECASE
                )
                if m:
                    d = int(m.group(1)) if m.group(1) else 0
                    h = int(m.group(2))
                    time_left = f"{d}D,{h}H ‚è≥" if d else f"{h}H ‚è≥"
                    break
        if not time_left:
            time_left = "N/A"

        cleaned_subscriptions = []
        for line in combined_subscriptions:
            if "#" in line:
                try:
                    base, meta = line.split("#", 1)
                except ValueError:
                    continue
                parts = meta.split("-")
                if SUPERNODE:
                    if parts:
                        country = parts[0]
                        if "_" in country:
                            country = country.split("_", 1)[1]
                        if len(parts) == 4:
                            meta_clean = country + "-" + parts[2]
                        elif len(parts) == 3:
                            meta_clean = country
                        else:
                            meta_clean = country
                    else:
                        meta_clean = ""
                else:
                    # –î–ª—è SUPERNODE=False:
                    if len(parts) >= 4:
                        meta_clean = parts[0] + "-" + parts[2]
                    elif len(parts) == 3:
                        if re.search(r'\d+[DH]', parts[1], re.IGNORECASE):
                            meta_clean = parts[0]
                        else:
                            meta_clean = parts[0] + "-" + parts[1]
                    elif len(parts) == 2:
                        meta_clean = parts[0]
                    elif parts:
                        meta_clean = parts[0]
                    else:
                        meta_clean = ""
                cleaned_line = base + "#" + meta_clean
            else:
                cleaned_line = line
            cleaned_subscriptions.append(cleaned_line)

        final_subscriptions = cleaned_subscriptions
        base64_encoded = base64.b64encode("\n".join(final_subscriptions).encode("utf-8")).decode("utf-8")
        subscription_info = f"üìÑ –ü–æ–¥–ø–∏—Å–∫–∞: {email} - {time_left}"

        user_agent = request.headers.get("User-Agent", "")
        if "Happ" in user_agent:
            encoded_project_name = f"{PROJECT_NAME}"
            support_username = SUPPORT_CHAT_URL.split("https://t.me/")[-1]
            announce_str = f"‚ÜñÔ∏è–ë–æ—Ç | {subscription_info} | –ü–æ–¥–¥–µ—Ä–∂–∫–∞‚ÜóÔ∏è"

            expire_timestamp = 0
            m_expire = re.search(r'(?:(\d+)D,)?(\d+)H', time_left)
            if m_expire:
                d = int(m_expire.group(1)) if m_expire.group(1) else 0
                h = int(m_expire.group(2))
                expire_timestamp = int(time.time() + d * 86400 + h * 3600)

            if TOTAL_GB != 0:
                country_remaining = {}
                for line in combined_subscriptions:
                    if "#" not in line:
                        continue
                    try:
                        _, meta = line.split("#", 1)
                    except ValueError:
                        continue
                    parts = meta.split("-")
                    if len(parts) == 4:
                        remaining_str = parts[2]
                    elif len(parts) == 3:
                        remaining_str = parts[1]
                    else:
                        remaining_str = ""
                    if remaining_str:
                        remaining_str = urllib.parse.unquote(remaining_str)
                        remaining_str = remaining_str.replace(',', '.')
                        remaining_str = re.sub(r'[^0-9\.GMKB]', '', remaining_str)
                        m_total = re.search(r'([\d\.]+)([GMK]B)', remaining_str, re.IGNORECASE)
                        if m_total:
                            value = float(m_total.group(1))
                            unit = m_total.group(2).upper()
                            if unit == "GB":
                                remaining_bytes = int(value * 1073741824)
                            elif unit == "MB":
                                remaining_bytes = int(value * 1048576)
                            elif unit == "KB":
                                remaining_bytes = int(value * 1024)
                            else:
                                remaining_bytes = int(value)
                            country = parts[0].strip()
                            country_remaining[country] = remaining_bytes
                num_countries = len(country_remaining)
                issued_per_country = TOTAL_GB
                total_traffic_bytes = issued_per_country * num_countries
                consumed_traffic_bytes = total_traffic_bytes - sum(country_remaining.values())
                if consumed_traffic_bytes < 0:
                    consumed_traffic_bytes = 0
            else:
                consumed_traffic_bytes = 0
                total_traffic_bytes = 0

            subscription_userinfo = f"upload=0; download={consumed_traffic_bytes}; total={total_traffic_bytes}; expire={expire_timestamp}"
            
            headers = {
                "Content-Type": "text/plain; charset=utf-8",
                "Content-Disposition": "inline",
                "profile-update-interval": "3",
                "profile-title": "base64:" + base64.b64encode(encoded_project_name.encode("utf-8")).decode("utf-8"),
                "support-url": SUPPORT_CHAT_URL,
                "announce": "base64:" + base64.b64encode(announce_str.encode("utf-8")).decode("utf-8"),
                "profile-web-page-url": f"https://t.me/{USERNAME_BOT}",
                "subscription-userinfo": subscription_userinfo
            }
        else:
            encoded_project_name = f"{PROJECT_NAME}\n{subscription_info}"
            headers = {
                "Content-Type": "text/plain; charset=utf-8",
                "Content-Disposition": "inline",
                "profile-update-interval": "3",
                "profile-title": "base64:" + base64.b64encode(encoded_project_name.encode("utf-8")).decode("utf-8")
            }

        logger.info(f"–í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏ –¥–ª—è email: {email}")
        return web.Response(text=base64_encoded, headers=headers)

async def handle_old_subscription(request):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤."""
    return await handle_subscription(request, old_subscription=True)


async def handle_new_subscription(request):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤."""
    return await handle_subscription(request, old_subscription=False)
